{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell",
   "metadata": {},
   "source": [
    "[//]: # ( Horticultural Data Analysis Template )\n",
    "[//]: # ( License: MIT License )\n",
    "[//]: # ( Repository: https://github.com/outobecca/botanical-colabs )\n",
    "\n",
    "# üî¨ Horticultural Data Analysis Template\n",
    "**Template Version 1.0** | Created: 2025-11-04\n",
    "\n",
    "## üìã Overview\n",
    "\n",
    "**Purpose:** Template for analyzing environmental sensor data, soil tests, and plant measurements.\n",
    "\n",
    "**Use this template for:** Loading and cleaning horticultural datasets, exploratory data analysis, anomaly detection, statistical summaries\n",
    "\n",
    "### üéØ Template Structure\n",
    "This specialized template includes:\n",
    "- Pre-configured imports and dependencies\n",
    "- Standard helper functions for this workflow type\n",
    "- Sample data generation functions\n",
    "- Visualization templates\n",
    "- Export and citation sections\n",
    "\n",
    "### üìù How to Use This Template\n",
    "1. Copy this notebook to create your analysis\n",
    "2. Update the header with your specific research question\n",
    "3. Modify sample data generators or add data loading\n",
    "4. Customize analysis and visualization sections\n",
    "5. Update citations with your data sources\n",
    "\n",
    "### ‚ö†Ô∏è Template Notes\n",
    "- Replace [brackets] with your specific content\n",
    "- Modify sample data to match your research\n",
    "- Add or remove sections as needed\n",
    "- Follow the established code style\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell",
   "metadata": {},
   "source": [
    "## üìö Background & Methodology\n\n### Scientific Context\nModern horticulture uses data from:\n- Environmental sensors (IoT devices, weather stations)\n- Soil laboratory analyses\n- Plant measurements (growth, yield)\n\nSystematic analysis helps optimize conditions and improve outcomes.\n\n### Methodology\n1. **Data Loading** - Import from files or generate samples\n2. **Data Cleaning** - Handle missing values and outliers\n3. **Exploratory Analysis** - Statistics and distributions\n4. **Visualization** - Charts and plots\n5. **Export** - Save results\n\n### Expected Outputs\n- Summary statistics\n- Time series plots\n- Distribution histograms\n- Correlation heatmaps\n- Cleaned datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 1: Installation and Configuration\n\nRun the cells below to install libraries and configure your analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell",
   "metadata": {},
   "source": [
    "# ============================================================================\n# Library Installation and Import\n# ============================================================================\n\"\"\"\nInstalls required Python libraries.\nRun this cell first.\n\"\"\"\n\n# Installation\n!pip install -q pandas numpy matplotlib seaborn scipy ipywidgets openpyxl plotly scikit-learn\n\n# Core imports\nfrom typing import Dict, Optional, List, Any, Tuple\nfrom IPython.display import display, Markdown, HTML\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport ipywidgets as widgets\nfrom datetime import datetime, timedelta\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set visualization style\nsns.set_style(\"whitegrid\")\nplt.rcParams['figure.figsize'] = (12, 6)\n\nprint(\"‚úÖ Libraries installed successfully\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "cell",
   "metadata": {},
   "source": [
    "# ============================================================================\n# Interactive Configuration\n# ============================================================================\n\n# Data source selection (FORM)\nprint(\"üìã SELECT DATA SOURCE:\")\ndata_source_options = {\n    '1': 'Sample Environmental Data (30 days of sensor readings)',\n    '2': 'Sample Soil Analysis Data (50 samples)',\n    '3': 'Sample Plant Growth Data (100 plants)',\n    '4': 'Upload My File (CSV, Excel, or JSON)'\n}\n\nfor key, desc in data_source_options.items():\n    print(f\"  [{key}] {desc}\")\n\nDATA_SOURCE_CHOICE = input(\"",
    "Enter choice (1-4): \").strip() or '1'\n\n# Upload file if needed\nUPLOADED_DATA = None\nif DATA_SOURCE_CHOICE == '4':\n    print(\"",
    "üì§ Upload your file in the next cell using Google Colab's file upload\")\n    from google.colab import files\n    uploaded = files.upload()\n    if uploaded:\n        filename = list(uploaded.keys())[0]\n        print(f\"‚úÖ Uploaded: {filename}\")\n        # Load the file\n        if filename.endswith('.csv'):\n            UPLOADED_DATA = pd.read_csv(filename)\n        elif filename.endswith(('.xlsx', '.xls')):\n            UPLOADED_DATA = pd.read_excel(filename)\n        elif filename.endswith('.json'):\n            UPLOADED_DATA = pd.read_json(filename)\n        print(f\"üìä Loaded {len(UPLOADED_DATA)} rows\")\n\n# Outlier handling (FORM)\nprint(\"",
    "üéØ OUTLIER DETECTION:\")\nprint(\"  [1] Remove outliers (Z-score method)\")\nprint(\"  [2] Remove outliers (IQR method)\")\nprint(\"  [3] Keep all data\")\n\nOUTLIER_CHOICE = input(\"Enter choice (1-3): \").strip() or '1'\nREMOVE_OUTLIERS = OUTLIER_CHOICE in ['1', '2']\nOUTLIER_METHOD = 'zscore' if OUTLIER_CHOICE == '1' else 'iqr'\n\nif REMOVE_OUTLIERS:\n    Z_THRESHOLD = float(input(\"Z-score threshold (default 3.0): \").strip() or '3.0')\nelse:\n    Z_THRESHOLD = 3.0\n\nprint(\"",
    "‚úÖ Configuration complete!\")\nprint(f\"   Data source: {data_source_options[DATA_SOURCE_CHOICE]}\")\nprint(f\"   Outlier handling: {OUTLIER_METHOD if REMOVE_OUTLIERS else 'None'}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cell",
   "metadata": {},
   "source": [
    "## üîß Step 2: Helper Functions\n\nData processing utilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell",
   "metadata": {},
   "source": [
    "# ============================================================================\n# Helper Functions\n# ============================================================================\n\ndef generate_environmental_data(days=30):\n    \"\"\"Generate sample environmental sensor data.\"\"\"\n    np.random.seed(42)\n    dates = pd.date_range(end=datetime.now(), periods=days*24, freq='H')\n    hours = np.array([d.hour for d in dates])\n    \n    # Realistic patterns\n    temp = 22 + 5 * np.sin((hours - 6) * np.pi / 12) + np.random.normal(0, 1, len(dates))\n    humidity = 60 - 15 * np.sin((hours - 6) * np.pi / 12) + np.random.normal(0, 3, len(dates))\n    light = np.maximum(0, 400 * np.sin((hours - 6) * np.pi / 12) + np.random.normal(0, 30, len(dates)))\n    \n    df = pd.DataFrame({\n        'timestamp': dates,\n        'temperature_c': temp,\n        'humidity_percent': humidity,\n        'light_ppfd': light,\n        'soil_moisture': 65 + np.random.normal(0, 5, len(dates))\n    })\n    \n    # Add anomalies\n    anomalies = np.random.choice(len(df), 5, replace=False)\n    df.loc[anomalies, 'temperature_c'] += np.random.choice([-10, 10], 5)\n    \n    return df\n\ndef generate_soil_data(n=50):\n    \"\"\"Generate sample soil analysis data.\"\"\"\n    np.random.seed(42)\n    return pd.DataFrame({\n        'sample_id': [f'SOIL_{i:03d}' for i in range(1, n+1)],\n        'location': np.random.choice(['Field A', 'Field B', 'Field C'], n),\n        'ph': np.clip(np.random.normal(6.5, 0.5, n), 5.0, 8.0),\n        'nitrogen_ppm': np.clip(np.random.normal(45, 10, n), 0, 100),\n        'phosphorus_ppm': np.clip(np.random.normal(30, 8, n), 0, 80),\n        'potassium_ppm': np.clip(np.random.normal(180, 30, n), 0, 300),\n        'organic_matter_%': np.clip(np.random.normal(4.5, 1.2, n), 1, 10),\n        'date': pd.date_range(end=datetime.now(), periods=n)\n    })\n\ndef generate_plant_data(n=100):\n    \"\"\"Generate sample plant growth data.\"\"\"\n    np.random.seed(42)\n    treatments = ['Control', 'Treatment A', 'Treatment B']\n    df = pd.DataFrame({\n        'plant_id': [f'P{i:04d}' for i in range(1, n+1)],\n        'variety': np.random.choice(['Var1', 'Var2', 'Var3'], n),\n        'treatment': np.random.choice(treatments, n),\n        'height_cm': np.random.normal(45, 12, n),\n        'leaf_count': np.random.poisson(25, n),\n        'yield_g': np.random.normal(125, 30, n),\n        'date': pd.date_range(end=datetime.now(), periods=n)[::-1]\n    })\n    \n    # Treatment effects\n    for treat, factor in {'Control': 1.0, 'Treatment A': 1.15, 'Treatment B': 1.25}.items():\n        mask = df['treatment'] == treat\n        df.loc[mask, ['height_cm', 'yield_g']] *= factor\n    \n    return df.clip(lower=0)\n\ndef detect_outliers(df, column, method='zscore', threshold=3.0):\n    \"\"\"Detect outliers in a column.\"\"\"\n    if method == 'zscore':\n        z = np.abs((df[column] - df[column].mean()) / df[column].std())\n        return z > threshold\n    else:  # IQR\n        Q1, Q3 = df[column].quantile([0.25, 0.75])\n        IQR = Q3 - Q1\n        return (df[column] < Q1 - 1.5*IQR) | (df[column] > Q3 + 1.5*IQR)\n\ndef clean_data(df, remove_outliers=True, method='zscore', threshold=3.0):\n    \"\"\"Clean dataframe.\"\"\"\n    df_clean = df.copy()\n    \n    # Fill missing values\n    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n    df_clean[numeric_cols] = df_clean[numeric_cols].fillna(df_clean[numeric_cols].median())\n    \n    # Remove outliers\n    if remove_outliers:\n        outlier_mask = pd.Series(False, index=df_clean.index)\n        for col in numeric_cols:\n            outlier_mask |= detect_outliers(df_clean, col, method, threshold)\n        df_clean = df_clean[~outlier_mask]\n        print(f\"üóëÔ∏è Removed {outlier_mask.sum()} outliers\")\n    \n    return df_clean\n\nprint(\"‚úÖ Helper functions loaded\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cell",
   "metadata": {},
   "source": [
    "## üì° Step 3: Load Data\n\nLoad the selected dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell",
   "metadata": {},
   "source": [
    "# ============================================================================\n# Load Data\n# ============================================================================\n\nif UPLOADED_DATA is not None:\n    data = UPLOADED_DATA\n    print(\"‚úÖ Using uploaded data\")\nelif DATA_SOURCE_CHOICE == '1':\n    data = generate_environmental_data(30)\n    print(\"‚úÖ Generated environmental data (720 readings)\")\nelif DATA_SOURCE_CHOICE == '2':\n    data = generate_soil_data(50)\n    print(\"‚úÖ Generated soil data (50 samples)\")\nelif DATA_SOURCE_CHOICE == '3':\n    data = generate_plant_data(100)\n    print(\"‚úÖ Generated plant growth data (100 plants)\")\nelse:\n    data = generate_environmental_data(30)\n    print(\"‚úÖ Using default environmental data\")\n\nprint(f\"",
    "üìä Dataset shape: {data.shape}\")\nprint(f\"üìã Columns: {list(data.columns)}\")\n\n# Preview\ndisplay(Markdown(\"### üîç Data Preview\"))\ndisplay(data.head(10))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cell",
   "metadata": {},
   "source": [
    "## üöÄ Step 4: Clean and Analyze Data\n\nClean the data and compute statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell",
   "metadata": {},
   "source": [
    "# ============================================================================\n# Data Cleaning and Analysis\n# ============================================================================\n\nprint(\"üîÑ Cleaning data...\")\ndata_clean = clean_data(data, REMOVE_OUTLIERS, OUTLIER_METHOD, Z_THRESHOLD)\n\nprint(f\"",
    "üìä Original: {len(data)} rows\")\nprint(f\"üìä Cleaned: {len(data_clean)} rows\")\n\n# Summary statistics\ndisplay(Markdown(\"### üìà Summary Statistics\"))\ndisplay(data_clean.describe())\n\n# Missing values\ndisplay(Markdown(\"### üîç Missing Values\"))\nmissing = data.isnull().sum()\nif missing.sum() > 0:\n    display(missing[missing > 0])\nelse:\n    print(\"‚úÖ No missing values\")\n\n# Data types\ndisplay(Markdown(\"### üìã Data Types\"))\ndisplay(pd.DataFrame({'Type': data_clean.dtypes, 'Count': data_clean.count()}))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cell",
   "metadata": {},
   "source": [
    "## üìä Step 5: Visualizations\n\nCreate exploratory visualizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell",
   "metadata": {},
   "source": [
    "# ============================================================================\n# Data Visualization\n# ============================================================================\n\nnumeric_cols = data_clean.select_dtypes(include=[np.number]).columns\n\n# Distribution plots\nif len(numeric_cols) > 0:\n    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n    axes = axes.flatten()\n    \n    for i, col in enumerate(numeric_cols[:4]):\n        axes[i].hist(data_clean[col].dropna(), bins=30, edgecolor='black', alpha=0.7)\n        axes[i].set_title(f'Distribution: {col}', fontweight='bold')\n        axes[i].set_xlabel(col)\n        axes[i].set_ylabel('Frequency')\n        axes[i].grid(True, alpha=0.3)\n    \n    # Hide extra subplots\n    for i in range(len(numeric_cols), 4):\n        axes[i].set_visible(False)\n    \n    plt.tight_layout()\n    plt.show()\n\n# Correlation heatmap\nif len(numeric_cols) > 1:\n    display(Markdown(\"### üî• Correlation Heatmap\"))\n    plt.figure(figsize=(10, 8))\n    corr = data_clean[numeric_cols].corr()\n    sns.heatmap(corr, annot=True, cmap='coolwarm', center=0, square=True, fmt='.2f')\n    plt.title('Correlation Matrix', fontsize=14, fontweight='bold')\n    plt.tight_layout()\n    plt.show()\n\n# Time series (if timestamp column exists)\ntime_col = [c for c in data_clean.columns if 'time' in c.lower() or 'date' in c.lower()]\nif time_col and len(numeric_cols) > 0:\n    display(Markdown(\"### üìÖ Time Series\"))\n    fig, ax = plt.subplots(figsize=(14, 6))\n    for col in numeric_cols[:3]:  # Plot first 3 numeric columns\n        ax.plot(data_clean[time_col[0]], data_clean[col], label=col, marker='o', markersize=2)\n    ax.set_xlabel('Time', fontsize=12)\n    ax.set_ylabel('Value', fontsize=12)\n    ax.set_title('Time Series Plot', fontsize=14, fontweight='bold')\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\nprint(\"‚úÖ Visualizations complete\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cell",
   "metadata": {},
   "source": [
    "## üìö Step 6: Export and Citations\n\nExport cleaned data and document sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell",
   "metadata": {},
   "source": [
    "# ============================================================================\n# Export Results\n# ============================================================================\n\n# Export cleaned data\nexport_filename = f\"cleaned_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\ndata_clean.to_csv(export_filename, index=False)\nprint(f\"‚úÖ Exported: {export_filename}\")\n\n# Summary report\ndisplay(Markdown(f\"\"\"\n### üìã Analysis Summary\n\n**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M')}  \n**Dataset:** {DATA_SOURCE_CHOICE}  \n**Original rows:** {len(data)}  \n**Cleaned rows:** {len(data_clean)}  \n**Columns:** {len(data_clean.columns)}  \n**Outlier method:** {OUTLIER_METHOD if REMOVE_OUTLIERS else 'None'}\n\n### üìö Data Sources\n- Sample data generated using NumPy (BSD License)\n- Analysis performed using Pandas and SciPy\n\n### üìñ Citation\nIf using this notebook, please cite:\n> Botanical Colabs (2025). Horticultural Data Analysis & Exploration. \n> https://github.com/outobecca/botanical-colabs\n\n### üìù Notes\n- Always verify results with domain experts\n- Sample data is for demonstration only\n- Clean uploaded data may have different characteristics\n\"\"\"))\n\nprint(\"",
    "‚úÖ Analysis complete!\")\n"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}