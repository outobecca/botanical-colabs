# ğŸ“¦ Batch Plant Cards

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/outobecca/botanical-colabs/blob/main/notebooks/examples/batch-plant-cards.ipynb)

> **Process multiple species simultaneously with progress tracking and automated exports**

---

## ğŸ“‹ Overview

The Batch Plant Cards notebook extends the [Plant Card Generator](Examples-Plant-Card-Generator) to handle **bulk processing** of multiple species. Perfect for creating comprehensive plant databases, field guides, or nursery catalogs with hundreds or thousands of species.

### Key Capabilities
- ğŸ“Š **CSV file upload** â€” Process species lists from spreadsheets
- ğŸ“ˆ **Progress tracking** â€” Real-time progress bars with tqdm
- ğŸ”„ **Error handling** â€” Continue processing even if individual species fail
- ğŸ’¾ **Multiple exports** â€” CSV, JSON, and HTML formats
- ğŸ“‰ **Results analysis** â€” Statistical summaries and family distribution
- â¸ï¸ **Rate limiting** â€” Configurable delays to respect API limits

---

## ğŸ¯ Use Cases

### Large-Scale Projects
- âœ… **Field guide creation** â€” Process 100+ species for regional guides
- âœ… **Nursery catalogs** â€” Generate descriptions for entire inventory
- âœ… **Research databases** â€” Build comprehensive species databases
- âœ… **Conservation projects** â€” Document endangered species lists
- âœ… **Educational materials** â€” Create classroom resources

### Data Management
- âœ… **Database migration** â€” Convert species lists to structured data
- âœ… **Quality assurance** â€” Batch validate species information
- âœ… **Data enrichment** â€” Add details to existing species lists
- âœ… **Format conversion** â€” CSV to JSON/HTML conversion
- âœ… **Automated updates** â€” Refresh species data periodically

---

## â­ Key Features

### CSV File Upload

**Interactive file upload:**
```python
# Upload your CSV file
csv_upload = widgets.FileUpload(
    accept='.csv',
    description='Upload CSV'
)
```

**Required CSV format:**
```csv
species_name
Rosa canina
Quercus robur
Betula pendula
Pinus sylvestris
```

**Optional columns:**
- `common_name` â€” Display name
- `priority` â€” Processing order
- `notes` â€” Internal comments

### Progress Tracking

**Real-time progress bar:**
```python
from tqdm.notebook import tqdm

for species in tqdm(species_list):
    # Process each species
    # Update progress automatically
```

**Features:**
- Estimated time remaining
- Processing speed (species/second)
- Current species name
- Success/failure counts

### Error Handling

**Robust failure management:**
```python
failed_species = []

for species in species_list:
    try:
        result = process_species(species)
        successful.append(result)
    except Exception as e:
        failed_species.append({
            'species': species,
            'error': str(e)
        })
        # Continue with next species
```

**Failed species log:**
- Species name
- Error message
- Timestamp
- Retry capability

### Multiple Export Formats

#### CSV Export
```python
# Export to CSV
df.to_csv('plant_cards_export.csv', index=False)
```

**Includes:**
- All fetched data fields
- Timestamps
- Source attribution
- Data quality indicators

#### JSON Export
```python
# Export to JSON
json_data = df.to_json(orient='records', indent=2)
```

**Structure:**
```json
[
  {
    "scientificName": "Rosa canina",
    "family": "Rosaceae",
    "commonNames": ["Dog Rose"],
    "characteristics": {...},
    "sources": [...]
  }
]
```

#### HTML Export
```python
# Export to styled HTML
html = df.to_html(
    classes='plant-table',
    escape=False
)
```

**Features:**
- Professional styling
- Sortable columns
- Responsive design
- Print-friendly

### Results Analysis

**Statistical summary:**
```python
# Summary statistics
total_species = len(results)
success_rate = len(successful) / total_species
avg_processing_time = total_time / total_species

# Family distribution
family_counts = df['family'].value_counts()
```

**Visualizations:**
- Family distribution bar chart
- Success/failure pie chart
- Processing time histogram
- Data completeness heatmap

---

## ğŸ“¦ What's Included

### Notebook Structure

1. **Introduction** â€” Batch processing overview
2. **Installation** â€” Required libraries (requests, pandas, tqdm, openpyxl)
3. **Configuration UI** â€” Interactive widgets for settings
4. **Data Input** â€” CSV upload and manual entry
5. **Helper Functions** â€” API wrappers and utilities
6. **Batch Processing Engine** â€” Main processing loop
7. **Progress Monitoring** â€” Real-time status updates
8. **Error Logging** â€” Failed species tracking
9. **Results Analysis** â€” Statistical summaries
10. **Data Visualization** â€” Charts and graphs
11. **Export Functions** â€” Multiple format exports
12. **Retry Mechanism** â€” Re-process failed species

### Processing Functions

```python
def process_species(
    species_name: str,
    language: str = 'en',
    api_keys: Dict[str, str] = None
) -> Dict[str, Any]:
    """
    Process a single species.
    
    Returns:
        Dictionary with all collected data
    """
    
def run_batch_processing(
    species_list: List[str],
    delay: float = 1.0,
    language: str = 'en'
) -> Tuple[List[Dict], List[Dict]]:
    """
    Process multiple species with progress tracking.
    
    Returns:
        Tuple of (successful_results, failed_species)
    """
```

---

## ğŸš€ Getting Started

### Method 1: CSV Upload (Recommended)

1. **Prepare CSV file:**
   ```csv
   species_name
   Rosa canina
   Quercus robur
   Betula pendula
   ```

2. **Open in Colab** â€” Click badge above

3. **Upload CSV:**
   - Click "Choose Files" button
   - Select your CSV file
   - Wait for upload confirmation

4. **Configure settings:**
   - Select language
   - Set delay between requests
   - Choose export formats

5. **Start processing:**
   - Click "Start Batch Processing"
   - Monitor progress bar
   - Wait for completion

6. **Download results:**
   - CSV export button
   - JSON export button
   - HTML export button

### Method 2: Manual Entry

1. **Enter species list:**
   ```python
   species_list = [
       "Rosa canina",
       "Quercus robur",
       "Betula pendula",
       # ... add more
   ]
   ```

2. **Configure and run:**
   ```python
   results = run_batch_processing(
       species_list,
       delay=1.0,
       language='en'
   )
   ```

3. **Export results:**
   ```python
   save_to_csv(results, 'output.csv')
   save_to_json(results, 'output.json')
   ```

---

## ğŸ’¡ Usage Examples

### Example 1: Small Batch (10-50 species)

```python
# Quick processing for small lists
species_list = [
    "Rosa canina",
    "Quercus robur",
    "Betula pendula",
    # ... 10 species total
]

# Fast processing (0.5s delay)
results, failed = run_batch_processing(
    species_list,
    delay=0.5,
    language='en'
)

# Quick export
export_to_csv(results)
```

**Estimated time:** 1-2 minutes

### Example 2: Medium Batch (50-200 species)

```python
# Upload CSV with 100 species
# Set delay to 1.0 seconds
# Process with progress tracking

# Estimated time: 5-10 minutes
```

**Features to use:**
- CSV upload
- Progress monitoring
- Error logging
- Batch export

### Example 3: Large Batch (200+ species)

```python
# Upload CSV with 500 species
# Set delay to 2.0 seconds (respect API limits)
# Enable retry for failed species

# Estimated time: 20-30 minutes
```

**Recommendations:**
- Run during off-peak hours
- Save intermediate results
- Monitor failed species
- Retry failures separately

### Example 4: Multi-language Database

```python
# Process in multiple languages
languages = ['en', 'fi', 'sv', 'de']

for lang in languages:
    results = run_batch_processing(
        species_list,
        language=lang,
        delay=1.5
    )
    export_to_csv(results, f'plants_{lang}.csv')
```

**Creates:**
- plants_en.csv
- plants_fi.csv
- plants_sv.csv
- plants_de.csv

---

## ğŸ“Š Performance

### Processing Speed

| Batch Size | Delay | Est. Time | Memory |
|------------|-------|-----------|--------|
| 10 species | 0.5s | 1 min | <50MB |
| 50 species | 1.0s | 3-5 min | <100MB |
| 100 species | 1.0s | 5-10 min | <200MB |
| 500 species | 2.0s | 20-30 min | <500MB |
| 1000 species | 2.0s | 40-60 min | <1GB |

### Optimization Tips

**Speed up processing:**
- âœ… Use lower delays for free APIs (0.5-1.0s)
- âœ… Process in parallel (advanced)
- âœ… Skip optional data sources
- âœ… Cache API responses

**Reduce failures:**
- âœ… Validate species names first
- âœ… Use higher delays for stability
- âœ… Implement retry logic
- âœ… Handle timeouts gracefully

**Save resources:**
- âœ… Export periodically (every 100 species)
- âœ… Clear outputs between batches
- âœ… Use Colab Pro for longer runtime
- âœ… Split into smaller batches

---

## ğŸ”§ Advanced Features

### Automatic Retry

```python
# Retry failed species with longer delay
if failed_species:
    print(f"Retrying {len(failed_species)} failed species...")
    
    retry_results, still_failed = run_batch_processing(
        [s['species'] for s in failed_species],
        delay=3.0,  # Longer delay
        language=language
    )
    
    # Combine with successful results
    all_results.extend(retry_results)
```

### Progress Checkpoint

```python
# Save progress every 50 species
checkpoint_interval = 50

for i, species in enumerate(species_list):
    result = process_species(species)
    results.append(result)
    
    if (i + 1) % checkpoint_interval == 0:
        save_checkpoint(results, f'checkpoint_{i+1}.csv')
```

### Custom Data Sources

```python
# Add custom data source to batch processing
def process_species_with_custom(species_name: str) -> Dict:
    # Standard processing
    data = process_species(species_name)
    
    # Add custom source
    custom_data = fetch_custom_api(species_name)
    data['custom'] = custom_data
    
    return data
```

### Parallel Processing

```python
from concurrent.futures import ThreadPoolExecutor

def parallel_batch_processing(species_list: List[str]) -> List[Dict]:
    """
    Process multiple species in parallel.
    Use with caution - respect API rate limits!
    """
    with ThreadPoolExecutor(max_workers=3) as executor:
        results = list(executor.map(process_species, species_list))
    return results
```

---

## ğŸ“ˆ Results Analysis

### Statistical Summary

```python
# Generate summary
summary = {
    'total_species': len(results),
    'successful': len(successful),
    'failed': len(failed),
    'success_rate': len(successful) / len(results),
    'families': df['family'].nunique(),
    'avg_processing_time': total_time / len(results)
}
```

### Family Distribution

```python
# Analyze family distribution
family_counts = df['family'].value_counts()

# Visualize
plt.figure(figsize=(12, 6))
family_counts.head(10).plot(kind='bar')
plt.title('Top 10 Plant Families')
plt.xlabel('Family')
plt.ylabel('Number of Species')
```

### Data Completeness

```python
# Check data completeness
completeness = {
    'has_description': df['description'].notna().sum(),
    'has_image': df['image_url'].notna().sum(),
    'has_care_info': df['care'].notna().sum(),
    'complete_records': df.notna().all(axis=1).sum()
}

# Completeness percentage
for key, value in completeness.items():
    pct = (value / len(df)) * 100
    print(f"{key}: {pct:.1f}%")
```

---

## ğŸ› Troubleshooting

### Common Issues

**CSV upload fails:**
- âœ… Check file format (UTF-8 encoding)
- âœ… Verify column name is "species_name"
- âœ… Remove empty rows
- âœ… Check for special characters

**Many species fail:**
- âœ… Verify species names are correct
- âœ… Increase delay between requests
- âœ… Check API keys are valid
- âœ… Retry failed species separately

**Processing too slow:**
- âœ… Reduce delay (if allowed by APIs)
- âœ… Skip optional data sources
- âœ… Process in smaller batches
- âœ… Use Colab Pro for faster runtime

**Memory errors:**
- âœ… Process in smaller batches
- âœ… Clear outputs periodically
- âœ… Export and restart for large datasets
- âœ… Use Colab Pro for more RAM

**Export fails:**
- âœ… Check file permissions
- âœ… Verify data format
- âœ… Try different export format
- âœ… Download in chunks

---

## ğŸ“š Related Resources

### Documentation
- [Plant Card Generator](Examples-Plant-Card-Generator) â€” Single species processing
- [Data Analysis Template](TEMPLATE-Data-Analysis) â€” Analyze exported data
- [API Setup Guide](https://github.com/outobecca/botanical-colabs/blob/main/API_SETUP.md)

### Data Sources
- [GBIF Backbone Taxonomy](https://www.gbif.org/dataset/d7dddbf4-2cf0-4f39-9b2a-bb099caae36c)
- [The Plant List](http://www.theplantlist.org) â€” Verify species names
- [World Flora Online](http://www.worldfloraonline.org) â€” Taxonomic validation

### Tools
- [OpenRefine](https://openrefine.org) â€” Clean species lists
- [Python pandas](https://pandas.pydata.org) â€” Data manipulation
- [tqdm](https://tqdm.github.io) â€” Progress bars

---

## ğŸ“„ License

MIT License â€” Free to use, modify, and distribute

**Citation:**
```bibtex
@software{batch_plant_cards_2025,
  author = {Sihvonen, Pekka},
  title = {Batch Plant Cards - Botanical Colabs},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/outobecca/botanical-colabs}
}
```

---

## ğŸ¤ Contributing

Improve batch processing!

- ğŸš€ Add parallel processing
- ğŸ’¾ Improve caching
- ğŸ“Š Better analytics
- ğŸ› Report bugs
- ğŸ’¡ Suggest features

[Submit Issues](https://github.com/outobecca/botanical-colabs/issues) | [Pull Requests](https://github.com/outobecca/botanical-colabs/pulls)

---

**Created:** 2025-11-04  
**Version:** 1.0  
**Status:** âœ… Production Ready

[â† Back to Examples](Home#-examples) | [View on GitHub](https://github.com/outobecca/botanical-colabs/blob/main/notebooks/examples/batch-plant-cards.ipynb)
